{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124997, 4)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import MinkowskiEngine as ME\n",
    "import open3d as o3d\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "def load_point_cloud(file_path):\n",
    "    point_cloud = np.fromfile(file_path, dtype=np.float32).reshape(-1, 4)\n",
    "    return point_cloud\n",
    "\n",
    "\n",
    "def load_labels(file_path):\n",
    "    labels = np.fromfile(file_path, dtype=np.uint32).reshape(-1)\n",
    "    # sem_label = np.fromfile(file_path, dtype=np.int16).reshape(-1)\n",
    "\n",
    "    return labels\n",
    "\n",
    "\n",
    "def quantize_point_cloud(point_cloud, labels, voxel_size=0.05):\n",
    "    # Quantize the point cloud\n",
    "    coordinates = point_cloud[:, :3]\n",
    "    features = point_cloud[:, 3:]\n",
    "    quantized_coords, quantized_features, unique_map, inverse_map = ME.utils.sparse_quantize(\n",
    "        coordinates=coordinates,\n",
    "        features=features,\n",
    "        return_index=True,\n",
    "        return_inverse=True,\n",
    "        quantization_size=voxel_size,\n",
    "    )\n",
    "    quantized_labels = labels[unique_map]\n",
    "    return quantized_coords, quantized_features, quantized_labels\n",
    "\n",
    "\n",
    "def save_data_item(data, velodyne_path, label_path):\n",
    "    # Combine coordinates and features\n",
    "    combined = np.hstack((data[\"coordinates\"], data[\"features\"]))\n",
    "    # Ensure parent directories exist\n",
    "    os.makedirs(os.path.dirname(velodyne_path), exist_ok=True)\n",
    "    os.makedirs(os.path.dirname(label_path), exist_ok=True)\n",
    "    # Save velodyne data\n",
    "    combined.astype(np.float32).tofile(velodyne_path)\n",
    "    # Save label data\n",
    "    data[\"labels\"].astype(np.uint32).tofile(label_path)\n",
    "\n",
    "\n",
    "def generate_distinct_colors_kmeans(n):\n",
    "    \"\"\"\n",
    "    Generate `n` distinct colors using k-means clustering.\n",
    "\n",
    "    Args:\n",
    "        n (int): Number of colors to generate.\n",
    "\n",
    "    Returns:\n",
    "        list of tuples: List of RGB color tuples.\n",
    "    \"\"\"\n",
    "    # Sample a large number of colors in RGB space\n",
    "    np.random.seed(0)\n",
    "    large_sample = np.random.randint(0, 256, (10000, 3))\n",
    "\n",
    "    # Apply k-means clustering to find n clusters\n",
    "    kmeans = KMeans(n_clusters=n, n_init=10).fit(large_sample)\n",
    "    colors = kmeans.cluster_centers_.astype(int)\n",
    "\n",
    "    return [tuple(color) for color in colors]\n",
    "\n",
    "\n",
    "def labels_to_colors(labels):\n",
    "    \"\"\"\n",
    "    Convert labels to colors using a k-means generated colormap.\n",
    "\n",
    "    Args:\n",
    "        labels (numpy.ndarray): Array of labels.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Array of RGB colors.\n",
    "    \"\"\"\n",
    "    # Determine the number of unique labels\n",
    "    unique_labels = np.unique(labels)\n",
    "    num_colors = len(unique_labels)\n",
    "\n",
    "    # Generate distinct colors\n",
    "    colors_list = generate_distinct_colors_kmeans(num_colors)\n",
    "\n",
    "    # Create a mapping from labels to colors\n",
    "    label_to_color = {label: colors_list[i] for i, label in enumerate(unique_labels)}\n",
    "\n",
    "    # Apply the color map\n",
    "    colors = np.array([label_to_color[label] for label in labels])\n",
    "    return colors\n",
    "\n",
    "\n",
    "def save_pcd(data, output_path):\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(data[\"coordinates\"])\n",
    "    colors = labels_to_colors(data[\"labels\"])[:, :3] / 255\n",
    "    # colors = labels_to_colors(data[\"labels\"])[:, :3]\n",
    "    pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "    o3d.io.write_point_cloud(output_path, pcd)\n",
    "    return colors\n",
    "\n",
    "\n",
    "scan_index = \"002503\"\n",
    "file_path = f\"/globalwork/data/SemanticKITTI/dataset/sequences/08/velodyne/{scan_index}.bin\"\n",
    "label_path = f\"/globalwork/data/SemanticKITTI/dataset/sequences/08/labels/{scan_index}.label\"\n",
    "\n",
    "point_cloud = load_point_cloud(file_path)\n",
    "labels = load_labels(label_path)\n",
    "colors = labels_to_colors(labels)[:, :3] / 255\n",
    "# quantized_coords, quantized_features, quantized_labels = quantize_point_cloud(point_cloud, labels, voxel_size=0.05)\n",
    "# data_item = {\"coordinates\": quantized_coords, \"features\": quantized_features, \"labels\": quantized_labels}\n",
    "data_item = {\"coordinates\": point_cloud[:, 0:3], \"features\": point_cloud[:, 3], \"labels\": labels}\n",
    "output_path = \"example.pcd\"\n",
    "save_pcd(data_item, output_path)\n",
    "\n",
    "\n",
    "# Create Open3D PointCloud object\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(point_cloud[:, :3])  # XYZ coordinates\n",
    "pcd.colors = o3d.utility.Vector3dVector(colors)  # RGB colors\n",
    "\n",
    "# Save as PLY file\n",
    "output_ply_path = \"example.ply\"\n",
    "o3d.io.write_point_cloud(output_ply_path, pcd)\n",
    "\n",
    "\n",
    "print(point_cloud.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import open3d as o3d\n",
    "\n",
    "ply_dtypes = dict([(b\"int8\", \"i1\"), (b\"char\", \"i1\"), (b\"uint8\", \"u1\"), (b\"uchar\", \"u1\"), (b\"int16\", \"i2\"), (b\"short\", \"i2\"), (b\"uint16\", \"u2\"), (b\"ushort\", \"u2\"), (b\"int32\", \"i4\"), (b\"int\", \"i4\"), (b\"uint32\", \"u4\"), (b\"uint\", \"u4\"), (b\"float32\", \"f4\"), (b\"float\", \"f4\"), (b\"float64\", \"f8\"), (b\"double\", \"f8\")])\n",
    "# Numpy reader format\n",
    "valid_formats = {\"ascii\": \"\", \"binary_big_endian\": \">\", \"binary_little_endian\": \"<\"}\n",
    "\n",
    "\n",
    "def read_ply(filename, triangular_mesh=False):\n",
    "    \"\"\"\n",
    "    Read \".ply\" files\n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : string\n",
    "        the name of the file to read.\n",
    "    Returns\n",
    "    -------\n",
    "    result : array\n",
    "    data stored in the file\n",
    "    Examples\n",
    "    --------\n",
    "    Store data in file\n",
    "    >>> points = np.random.rand(5, 3)\n",
    "    >>> values = np.random.randint(2, size=10)\n",
    "    >>> write_ply('example.ply', [points, values], ['x', 'y', 'z', 'values'])\n",
    "    Read the file\n",
    "    >>> data = read_ply('example.ply')\n",
    "    >>> values = data['values']\n",
    "    array([0, 0, 1, 1, 0])\n",
    "\n",
    "    >>> points = np.vstack((data['x'], data['y'], data['z'])).T\n",
    "    array([[ 0.466  0.595  0.324]\n",
    "           [ 0.538  0.407  0.654]\n",
    "           [ 0.850  0.018  0.988]\n",
    "           [ 0.395  0.394  0.363]\n",
    "           [ 0.873  0.996  0.092]])\n",
    "    \"\"\"\n",
    "\n",
    "    with open(filename, \"rb\") as plyfile:\n",
    "\n",
    "        # Check if the file start with ply\n",
    "        if b\"ply\" not in plyfile.readline():\n",
    "            raise ValueError(\"The file does not start whith the word ply\")\n",
    "\n",
    "        # get binary_little/big or ascii\n",
    "        fmt = plyfile.readline().split()[1].decode()\n",
    "        if fmt == \"ascii\":\n",
    "            raise ValueError(\"The file is not binary\")\n",
    "\n",
    "        # get extension for building the numpy dtypes\n",
    "        ext = valid_formats[fmt]\n",
    "\n",
    "        # PointCloud reader vs mesh reader\n",
    "        if triangular_mesh:\n",
    "\n",
    "            # Parse header\n",
    "            num_points, num_faces, properties = parse_mesh_header(plyfile, ext)\n",
    "\n",
    "            # Get point data\n",
    "            vertex_data = np.fromfile(plyfile, dtype=properties, count=num_points)\n",
    "\n",
    "            # Get face data\n",
    "            face_properties = [(\"k\", ext + \"u1\"), (\"v1\", ext + \"i4\"), (\"v2\", ext + \"i4\"), (\"v3\", ext + \"i4\")]\n",
    "            faces_data = np.fromfile(plyfile, dtype=face_properties, count=num_faces)\n",
    "\n",
    "            # Return vertex data and concatenated faces\n",
    "            faces = np.vstack((faces_data[\"v1\"], faces_data[\"v2\"], faces_data[\"v3\"])).T\n",
    "            data = [vertex_data, faces]\n",
    "\n",
    "        else:\n",
    "\n",
    "            # Parse header\n",
    "            num_points, properties = parse_header(plyfile, ext)\n",
    "\n",
    "            # Get data\n",
    "            data = np.fromfile(plyfile, dtype=properties, count=num_points)\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def parse_header(plyfile, ext):\n",
    "    # Variables\n",
    "    line = []\n",
    "    properties = []\n",
    "    num_points = None\n",
    "\n",
    "    while b\"end_header\" not in line and line != b\"\":\n",
    "        line = plyfile.readline()\n",
    "\n",
    "        if b\"element\" in line:\n",
    "            line = line.split()\n",
    "            num_points = int(line[2])\n",
    "\n",
    "        elif b\"property\" in line:\n",
    "            line = line.split()\n",
    "            properties.append((line[2].decode(), ext + ply_dtypes[line[1]]))\n",
    "\n",
    "    return num_points, properties\n",
    "\n",
    "\n",
    "def parse_mesh_header(plyfile, ext):\n",
    "    # Variables\n",
    "    line = []\n",
    "    vertex_properties = []\n",
    "    num_points = None\n",
    "    num_faces = None\n",
    "    current_element = None\n",
    "\n",
    "    while b\"end_header\" not in line and line != b\"\":\n",
    "        line = plyfile.readline()\n",
    "\n",
    "        # Find point element\n",
    "        if b\"element vertex\" in line:\n",
    "            current_element = \"vertex\"\n",
    "            line = line.split()\n",
    "            num_points = int(line[2])\n",
    "\n",
    "        elif b\"element face\" in line:\n",
    "            current_element = \"face\"\n",
    "            line = line.split()\n",
    "            num_faces = int(line[2])\n",
    "\n",
    "        elif b\"property\" in line:\n",
    "            if current_element == \"vertex\":\n",
    "                line = line.split()\n",
    "                vertex_properties.append((line[2].decode(), ext + ply_dtypes[line[1]]))\n",
    "            elif current_element == \"vertex\":\n",
    "                if not line.startswith(\"property list uchar int\"):\n",
    "                    raise ValueError(\"Unsupported faces property : \" + line)\n",
    "\n",
    "    return num_points, num_faces, vertex_properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"_pydevd_bundle/pydevd_cython.pyx\", line 577, in _pydevd_bundle.pydevd_cython.PyDBFrame._handle_exception\n",
      "  File \"_pydevd_bundle/pydevd_cython.pyx\", line 312, in _pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\n",
      "  File \"/home/fradlin/miniconda3/envs/mask4d/lib/python3.8/site-packages/debugpy/_vendored/pydevd/pydevd.py\", line 2070, in do_wait_suspend\n",
      "    keep_suspended = self._do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n",
      "  File \"/home/fradlin/miniconda3/envs/mask4d/lib/python3.8/site-packages/debugpy/_vendored/pydevd/pydevd.py\", line 2106, in _do_wait_suspend\n",
      "    time.sleep(0.01)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'read_ply' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Read the PLY file\u001b[39;00m\n\u001b[1;32m      5\u001b[0m ply_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/work/fradlin/Interactive_dataset/interactive4d_data/scene_01_SemanticKITTI_08_000238/label.ply\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m pcd \u001b[38;5;241m=\u001b[39m \u001b[43mread_ply\u001b[49m(ply_path)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Access the labels\u001b[39;00m\n\u001b[1;32m      9\u001b[0m labels \u001b[38;5;241m=\u001b[39m pcd[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mint32)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'read_ply' is not defined"
     ]
    }
   ],
   "source": [
    "# Define the color map\n",
    "label_color_map = {1: [1, 211, 211], 2: [233, 138, 0], 3: [41, 207, 2], 4: [244, 0, 128], 5: [194, 193, 3], 6: [121, 59, 50], 7: [254, 180, 214], 8: [239, 1, 51], 9: [125, 0, 237], 10: [229, 14, 241], 11: [222, 40, 0], 12: [0, 120, 231], 13: [110, 218, 96], 14: [253, 94, 83], 15: [153, 85, 187]}\n",
    "\n",
    "# Read the PLY file\n",
    "ply_path = \"/work/fradlin/Interactive_dataset/interactive4d_data/scene_01_SemanticKITTI_08_000238/label.ply\"\n",
    "pcd = read_ply(ply_path)\n",
    "\n",
    "# Access the labels\n",
    "labels = pcd[\"label\"].astype(np.int32)\n",
    "\n",
    "# Initialize an array for the new colors\n",
    "new_colors = np.zeros((len(labels), 3), dtype=np.uint8)\n",
    "\n",
    "# Map each label to the corresponding color\n",
    "for label, color in label_color_map.items():\n",
    "    new_colors[labels == label] = color\n",
    "\n",
    "# Update the point cloud with the new colors\n",
    "pcd[\"red\"] = new_colors[:, 0]\n",
    "pcd[\"green\"] = new_colors[:, 1]\n",
    "pcd[\"blue\"] = new_colors[:, 2]\n",
    "\n",
    "write_ply(ply_path, [pcd], [\"x\", \"y\", \"z\", \"red\", \"green\", \"blue\"])\n",
    "ply_path = \"/work/fradlin/Interactive_dataset/interactive4d_data/scene_01_SemanticKITTI_08_000238/scan.ply\"\n",
    "write_ply(ply_path, [pcd], [\"x\", \"y\", \"z\", \"red\", \"green\", \"blue\"])\n",
    "\n",
    "# Convert the updated PLY data to an Open3D point cloud\n",
    "o3d_pcd = o3d.geometry.PointCloud()\n",
    "o3d_pcd.points = o3d.utility.Vector3dVector(np.vstack([pcd[\"x\"], pcd[\"y\"], pcd[\"z\"]]).T)\n",
    "o3d_pcd.colors = o3d.utility.Vector3dVector(new_colors / 255.0)  # Normalize colors to [0, 1] range for Open3D\n",
    "\n",
    "# Visualize the point cloud\n",
    "# o3d.visualization.draw_geometries([o3d_pcd])\n",
    "\n",
    "# Optionally, save the updated point cloud to a new PLY file\n",
    "# o3d.io.write_point_cloud(\"updated_label.ply\", o3d_pcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "# Define the color map\n",
    "label_color_map = {1: [1, 211, 211], 2: [233, 138, 0], 3: [41, 207, 2], 4: [244, 0, 128], 5: [194, 193, 3], 6: [121, 59, 50], 7: [254, 180, 214], 8: [239, 1, 51], 9: [125, 0, 237], 10: [229, 14, 241], 11: [222, 40, 0], 12: [0, 120, 231], 13: [110, 218, 96], 14: [253, 94, 83], 15: [153, 85, 187]}\n",
    "\n",
    "# Define the size of each color box and the spacing\n",
    "box_size = 50\n",
    "spacing = 10\n",
    "\n",
    "# Calculate the image size\n",
    "num_labels = len(label_color_map)\n",
    "image_width = box_size + 100  # additional space for label text\n",
    "image_height = num_labels * (box_size + spacing)\n",
    "\n",
    "# Create a blank image\n",
    "image = Image.new(\"RGB\", (image_width, image_height), color=\"white\")\n",
    "draw = ImageDraw.Draw(image)\n",
    "\n",
    "# Draw the color boxes with labels\n",
    "for i, (label, color) in enumerate(label_color_map.items()):\n",
    "    y_position = i * (box_size + spacing)\n",
    "    # Draw the color box\n",
    "    draw.rectangle([0, y_position, box_size, y_position + box_size], fill=tuple(color))\n",
    "    # Draw the label text\n",
    "    draw.text((box_size + spacing, y_position + box_size // 4), f\"Label {label}\", fill=\"black\")\n",
    "\n",
    "# Save the image\n",
    "image.save(\"color_map_visualization.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['scene_08_000000', 'scene_08_000015', 'scene_08_000030', 'scene_08_000045', 'scene_08_000060', 'scene_08_000075', 'scene_08_000090', 'scene_08_000105', 'scene_08_000120', 'scene_08_000135', 'scene_08_000150', 'scene_08_000165', 'scene_08_000180', 'scene_08_000195', 'scene_08_000210', 'scene_08_000225', 'scene_08_000240', 'scene_08_000255', 'scene_08_000270', 'scene_08_000285', 'scene_08_000300', 'scene_08_000315', 'scene_08_000330', 'scene_08_000345', 'scene_08_000360', 'scene_08_000375', 'scene_08_000390', 'scene_08_000405', 'scene_08_000420', 'scene_08_000435', 'scene_08_000450', 'scene_08_000465', 'scene_08_000480', 'scene_08_000495', 'scene_08_000510', 'scene_08_000525', 'scene_08_000540', 'scene_08_000555', 'scene_08_000570', 'scene_08_000585', 'scene_08_000600', 'scene_08_000615', 'scene_08_000630', 'scene_08_000645', 'scene_08_000660', 'scene_08_000675', 'scene_08_000690', 'scene_08_000705', 'scene_08_000720', 'scene_08_000735', 'scene_08_000750', 'scene_08_000765', 'scene_08_000780', 'scene_08_000795', 'scene_08_000810', 'scene_08_000825', 'scene_08_000840', 'scene_08_000855', 'scene_08_000870', 'scene_08_000885', 'scene_08_000900', 'scene_08_000915', 'scene_08_000930', 'scene_08_000945', 'scene_08_000960', 'scene_08_000975', 'scene_08_000990', 'scene_08_001005', 'scene_08_001020', 'scene_08_001035', 'scene_08_001050', 'scene_08_001065', 'scene_08_001080', 'scene_08_001095', 'scene_08_001110', 'scene_08_001125', 'scene_08_001140', 'scene_08_001155', 'scene_08_001170', 'scene_08_001185', 'scene_08_001200', 'scene_08_001215', 'scene_08_001230', 'scene_08_001245', 'scene_08_001260', 'scene_08_001275', 'scene_08_001290', 'scene_08_001305', 'scene_08_001320', 'scene_08_001335', 'scene_08_001350', 'scene_08_001365', 'scene_08_001380', 'scene_08_001395', 'scene_08_001410', 'scene_08_001425', 'scene_08_001440', 'scene_08_001455', 'scene_08_001470', 'scene_08_001485', 'scene_08_001500', 'scene_08_001515', 'scene_08_001530', 'scene_08_001545', 'scene_08_001560', 'scene_08_001575', 'scene_08_001590', 'scene_08_001605', 'scene_08_001620', 'scene_08_001635', 'scene_08_001650', 'scene_08_001665', 'scene_08_001680', 'scene_08_001695', 'scene_08_001710', 'scene_08_001725', 'scene_08_001740', 'scene_08_001755', 'scene_08_001770', 'scene_08_001785', 'scene_08_001800', 'scene_08_001815', 'scene_08_001830', 'scene_08_001845', 'scene_08_001860', 'scene_08_001875', 'scene_08_001890', 'scene_08_001905', 'scene_08_001920', 'scene_08_001935', 'scene_08_001950', 'scene_08_001965', 'scene_08_001980', 'scene_08_001995', 'scene_08_002010', 'scene_08_002025', 'scene_08_002040', 'scene_08_002055', 'scene_08_002070', 'scene_08_002085', 'scene_08_002100', 'scene_08_002115', 'scene_08_002130', 'scene_08_002145', 'scene_08_002160', 'scene_08_002175', 'scene_08_002190', 'scene_08_002205', 'scene_08_002220', 'scene_08_002235', 'scene_08_002250', 'scene_08_002265', 'scene_08_002280', 'scene_08_002295', 'scene_08_002310', 'scene_08_002325', 'scene_08_002340', 'scene_08_002355', 'scene_08_002370', 'scene_08_002385', 'scene_08_002400', 'scene_08_002415', 'scene_08_002430', 'scene_08_002445', 'scene_08_002460', 'scene_08_002475', 'scene_08_002490', 'scene_08_002505', 'scene_08_002520', 'scene_08_002535', 'scene_08_002550', 'scene_08_002565', 'scene_08_002580', 'scene_08_002595', 'scene_08_002610', 'scene_08_002625', 'scene_08_002640', 'scene_08_002655', 'scene_08_002670', 'scene_08_002685', 'scene_08_002700', 'scene_08_002715', 'scene_08_002730', 'scene_08_002745', 'scene_08_002760', 'scene_08_002775', 'scene_08_002790', 'scene_08_002805', 'scene_08_002820', 'scene_08_002835', 'scene_08_002850', 'scene_08_002865', 'scene_08_002880', 'scene_08_002895', 'scene_08_002910', 'scene_08_002925', 'scene_08_002940', 'scene_08_002955', 'scene_08_002970', 'scene_08_002985', 'scene_08_003000', 'scene_08_003015', 'scene_08_003030', 'scene_08_003045', 'scene_08_003060', 'scene_08_003075', 'scene_08_003090', 'scene_08_003105', 'scene_08_003120', 'scene_08_003135', 'scene_08_003150', 'scene_08_003165', 'scene_08_003180', 'scene_08_003195', 'scene_08_003210', 'scene_08_003225', 'scene_08_003240', 'scene_08_003255', 'scene_08_003270', 'scene_08_003285', 'scene_08_003300', 'scene_08_003315', 'scene_08_003330', 'scene_08_003345', 'scene_08_003360', 'scene_08_003375', 'scene_08_003390', 'scene_08_003405', 'scene_08_003420', 'scene_08_003435', 'scene_08_003450', 'scene_08_003465', 'scene_08_003480', 'scene_08_003495', 'scene_08_003510', 'scene_08_003525', 'scene_08_003540', 'scene_08_003555', 'scene_08_003570', 'scene_08_003585', 'scene_08_003600', 'scene_08_003615', 'scene_08_003630', 'scene_08_003645', 'scene_08_003660', 'scene_08_003675', 'scene_08_003690', 'scene_08_003705', 'scene_08_003720', 'scene_08_003735', 'scene_08_003750', 'scene_08_003765', 'scene_08_003780', 'scene_08_003795', 'scene_08_003810', 'scene_08_003825', 'scene_08_003840', 'scene_08_003855', 'scene_08_003870', 'scene_08_003885', 'scene_08_003900', 'scene_08_003915', 'scene_08_003930', 'scene_08_003945', 'scene_08_003960', 'scene_08_003975', 'scene_08_003990', 'scene_08_004005', 'scene_08_004020', 'scene_08_004035', 'scene_08_004050', 'scene_08_004065'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "dir_path = Path(\"/nodes/veltins/work/fradlin/jsons\")\n",
    "new_json_file = dir_path.joinpath(dir_path, \"semantickitti_ablation_validation_list.json\")\n",
    "with open(new_json_file) as f:\n",
    "    data = json.load(f)\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "# Define the color map\n",
    "label_color_map = {1: [1, 211, 211], 2: [233, 138, 0], 3: [41, 207, 2], 4: [244, 0, 128], 5: [194, 193, 3], 6: [121, 59, 50], 7: [254, 180, 214], 8: [239, 1, 51], 9: [85, 85, 85], 10: [229, 14, 241]}\n",
    "# Define the size of each color box and the spacing\n",
    "box_size = 50\n",
    "spacing = 10\n",
    "\n",
    "# Calculate the image size\n",
    "num_labels = len(label_color_map)\n",
    "image_width = box_size + 100  # additional space for label text\n",
    "image_height = num_labels * (box_size + spacing)\n",
    "\n",
    "# Create a blank image\n",
    "image = Image.new(\"RGB\", (image_width, image_height), color=\"white\")\n",
    "draw = ImageDraw.Draw(image)\n",
    "\n",
    "# Draw the color boxes with labels\n",
    "for i, (label, color) in enumerate(label_color_map.items()):\n",
    "    y_position = i * (box_size + spacing)\n",
    "    # Draw the color box\n",
    "    draw.rectangle([0, y_position, box_size, y_position + box_size], fill=tuple(color))\n",
    "    # Draw the label text\n",
    "    draw.text((box_size + spacing, y_position + box_size // 4), f\"Label {label}\", fill=\"black\")\n",
    "\n",
    "# Save the image\n",
    "image.save(\"interactive_tool/color_map_visualization.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsample from the json list only every 15th element\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "dir_path = Path(\"/nodes/veltins/work/fradlin/jsons\")\n",
    "\n",
    "json_file = dir_path.joinpath(\"semantickitti_full_validation_list.json\")\n",
    "with open(json_file) as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# subsample from the json list only every 15th element\n",
    "subsampled_data = {}\n",
    "counter = 0\n",
    "for key, value in data.items():\n",
    "    # check if divisible by 15\n",
    "    if counter % 15 == 0:\n",
    "        subsampled_data[key] = value\n",
    "    counter += 1\n",
    "\n",
    "\n",
    "# write the subsampled data to a new file\n",
    "new_json_file = dir_path.joinpath(dir_path, \"semantickitti_ablation_validation_list.json\")\n",
    "\n",
    "with open(new_json_file, \"w\") as f:\n",
    "    json.dump(subsampled_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "std::vector<Eigen::Vector3d> with 114692 elements.\n",
       "Use numpy.asarray() to access data."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "scene_3dpoints_file = \"/work/fradlin/Interactive_dataset/interactive4d_data/scene_02_KITTI360_0000011079_0000011287/scan.ply\"\n",
    "lable_path = \"/work/fradlin/Interactive_dataset/interactive4d_data/scene_02_KITTI360_0000011079_0000011287/label.ply\"\n",
    "\n",
    "point_cloud = read_ply(lable_path)\n",
    "labels_full_ori = point_cloud[\"label\"].astype(np.int32)\n",
    "\n",
    "scene_3dpoints = o3d.io.read_point_cloud(scene_3dpoints_file)\n",
    "scene_3dpoints.points\n",
    "\n",
    "# self.scene_name, self.scene_point_type, self.points, labels_full_ori, record_file, mask_folder, click_folder, objects = self.dataloader_test.load_scene(curr_scene_idx - 1)\n",
    "# return name, self.point_type, self.scene_3dpoints, self.labels_full_ori, self.record_path, self.mask_folder, self.click_folder, [self.underscore_to_blank(name) for name in self.scene_object_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000003.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000009.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000025.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000026.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000028.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000029.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000030.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000031.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000032.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000035.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000037.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000038.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000039.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000040.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000041.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000042.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000043.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000044.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000045.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000046.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000047.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000048.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000049.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000050.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000051.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000052.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000053.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000054.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000055.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000056.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000057.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000060.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000061.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000062.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000063.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000064.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000065.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000066.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000068.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000069.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000070.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000071.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000072.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000073.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000074.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000075.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000076.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000077.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000078.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000079.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000080.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000081.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000082.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000083.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000084.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000085.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000086.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000087.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000088.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000089.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000090.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000091.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000092.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000093.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000094.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000095.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000096.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000116.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000117.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000118.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000139.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000143.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000145.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000147.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000148.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000151.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000152.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000154.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000155.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000156.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000157.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000158.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000159.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000160.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000161.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000162.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000163.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000164.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000165.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000166.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000167.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000168.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000169.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000170.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000171.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000196.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000197.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000198.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000199.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000200.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000201.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000202.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000203.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000204.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000205.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000206.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000207.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000208.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000209.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000210.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000211.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000517.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000518.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000519.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000520.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000521.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000522.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000523.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000524.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000525.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000536.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000537.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000556.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000557.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000558.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000559.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000560.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000576.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000577.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000578.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000579.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000580.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000581.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000582.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000903.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000904.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000907.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000908.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000909.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000910.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000911.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000912.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000913.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000914.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000915.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000916.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000917.bin\n",
      "/globalwork/data/SemanticKITTI/dataset/sequences/10/velodyne/000918.bin\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "with open(\"/globalwork/fradlin/mask4d-interactive/processed/semantic_kitti/full_train_list.json\", \"r\") as f:\n",
    "    train_list = json.load(f)\n",
    "\n",
    "updated_validation_list = {}\n",
    "for key, item in train_list.items():\n",
    "    new_item = item\n",
    "    new_item[\"number_of_objects\"] = len(item[\"unique_panoptic_labels\"])\n",
    "    updated_validation_list[key] = new_item\n",
    "    if len(item[\"unique_panoptic_labels\"]) == 10 and \"scene_10\" in key:\n",
    "        scan = key.split(\"_\")[2]\n",
    "        print(item[\"filepath\"])\n",
    "\n",
    "# write the updated validation list\n",
    "# with open(\"train_list.json\", \"w\") as f:\n",
    "#     json.dump(updated_validation_list, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import colorsys\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This Notebook is used for small utility tasks that need to be executed only once\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stats for training set\n",
      "The average number of unique_panoptic_labels is: 19.813904861474125\n",
      "The key with the largest unique_panoptic_labels is: scene_00_001472\n",
      "The largest number of unique_panoptic_labels is: 66\n",
      "The key with the smallest unique_panoptic_labels is: scene_02_001856\n",
      "The smallest number of unique_panoptic_labels is: 4\n"
     ]
    }
   ],
   "source": [
    "# Load the training JSON file\n",
    "with open(\"/globalwork/fradlin/mask4d-interactive/processed/semantic_kitti/full_train_list.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Initialize a variable to track the maximum length\n",
    "max_length = 0\n",
    "min_length = 1000000\n",
    "max_key = None\n",
    "min_key = None\n",
    "running_average = 0\n",
    "counter = 0\n",
    "\n",
    "# Iterate over all the keys in the JSON data\n",
    "for key, value in data.items():\n",
    "    if \"unique_panoptic_labels\" in value:\n",
    "        # Calculate the length of the unique_panoptic_labels list\n",
    "        length = len(value[\"unique_panoptic_labels\"])\n",
    "        # Update max_length if the current length is greater\n",
    "        if length > max_length:\n",
    "            max_length = length\n",
    "            max_key = key\n",
    "        if length < min_length:\n",
    "            min_length = length\n",
    "            min_key = key\n",
    "        running_average += length\n",
    "        counter += 1\n",
    "\n",
    "average = running_average / counter\n",
    "\n",
    "print(\"stats for training set\")\n",
    "print(f\"The average number of unique_panoptic_labels is: {average}\")\n",
    "print(f\"The key with the largest unique_panoptic_labels is: {max_key}\")\n",
    "print(f\"The largest number of unique_panoptic_labels is: {max_length}\")\n",
    "print(f\"The key with the smallest unique_panoptic_labels is: {min_key}\")\n",
    "print(f\"The smallest number of unique_panoptic_labels is: {min_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stats for validation set\n",
      "The average number of unique_panoptic_labels is: 24.574551707197248\n",
      "The key with the largest unique_panoptic_labels is: scene_08_004000\n",
      "The largest number of unique_panoptic_labels is: 54\n",
      "The key with the smallest unique_panoptic_labels is: scene_08_000236\n",
      "The smallest number of unique_panoptic_labels is: 11\n"
     ]
    }
   ],
   "source": [
    "# Load the validation JSON file\n",
    "with open(\"/globalwork/fradlin/mask4d-interactive/processed/semantic_kitti/full_validation_list.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Initialize a variable to track the maximum length\n",
    "max_length = 0\n",
    "min_length = 1000000\n",
    "max_key = None\n",
    "min_key = None\n",
    "running_average = 0\n",
    "counter = 0\n",
    "\n",
    "# Iterate over all the keys in the JSON data\n",
    "for key, value in data.items():\n",
    "    if \"unique_panoptic_labels\" in value:\n",
    "        # Calculate the length of the unique_panoptic_labels list\n",
    "        length = len(value[\"unique_panoptic_labels\"])\n",
    "        # Update max_length if the current length is greater\n",
    "        if length > max_length:\n",
    "            max_length = length\n",
    "            max_key = key\n",
    "        if length < min_length:\n",
    "            min_length = length\n",
    "            min_key = key\n",
    "        running_average += length\n",
    "        counter += 1\n",
    "\n",
    "average = running_average / counter\n",
    "\n",
    "print(\"stats for validation set\")\n",
    "print(f\"The average number of unique_panoptic_labels is: {average}\")\n",
    "print(f\"The key with the largest unique_panoptic_labels is: {max_key}\")\n",
    "print(f\"The largest number of unique_panoptic_labels is: {max_length}\")\n",
    "print(f\"The key with the smallest unique_panoptic_labels is: {min_key}\")\n",
    "print(f\"The smallest number of unique_panoptic_labels is: {min_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate n visually seperable RGB colors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Color 0: (242, 12, 12)\n",
      "Color 1: (242, 32, 12)\n",
      "Color 2: (242, 52, 12)\n",
      "Color 3: (242, 71, 12)\n",
      "Color 4: (242, 91, 12)\n",
      "Color 5: (242, 111, 12)\n",
      "Color 6: (242, 130, 12)\n",
      "Color 7: (242, 150, 12)\n",
      "Color 8: (242, 170, 12)\n",
      "Color 9: (242, 189, 12)\n",
      "Color 10: (242, 209, 12)\n",
      "Color 11: (242, 229, 12)\n",
      "Color 12: (235, 242, 12)\n",
      "Color 13: (216, 242, 12)\n",
      "Color 14: (196, 242, 12)\n",
      "Color 15: (176, 242, 12)\n",
      "Color 16: (157, 242, 12)\n",
      "Color 17: (137, 242, 12)\n",
      "Color 18: (117, 242, 12)\n",
      "Color 19: (97, 242, 12)\n",
      "Color 20: (78, 242, 12)\n",
      "Color 21: (58, 242, 12)\n",
      "Color 22: (38, 242, 12)\n",
      "Color 23: (19, 242, 12)\n",
      "Color 24: (12, 242, 25)\n",
      "Color 25: (12, 242, 45)\n",
      "Color 26: (12, 242, 65)\n",
      "Color 27: (12, 242, 84)\n",
      "Color 28: (12, 242, 104)\n",
      "Color 29: (12, 242, 124)\n",
      "Color 30: (12, 242, 143)\n",
      "Color 31: (12, 242, 163)\n",
      "Color 32: (12, 242, 183)\n",
      "Color 33: (12, 242, 202)\n",
      "Color 34: (12, 242, 222)\n",
      "Color 35: (12, 242, 242)\n",
      "Color 36: (12, 222, 242)\n",
      "Color 37: (12, 202, 242)\n",
      "Color 38: (12, 183, 242)\n",
      "Color 39: (12, 163, 242)\n",
      "Color 40: (12, 143, 242)\n",
      "Color 41: (12, 124, 242)\n",
      "Color 42: (12, 104, 242)\n",
      "Color 43: (12, 84, 242)\n",
      "Color 44: (12, 65, 242)\n",
      "Color 45: (12, 45, 242)\n",
      "Color 46: (12, 25, 242)\n",
      "Color 47: (19, 12, 242)\n",
      "Color 48: (38, 12, 242)\n",
      "Color 49: (58, 12, 242)\n",
      "Color 50: (78, 12, 242)\n",
      "Color 51: (97, 12, 242)\n",
      "Color 52: (117, 12, 242)\n",
      "Color 53: (137, 12, 242)\n",
      "Color 54: (157, 12, 242)\n",
      "Color 55: (176, 12, 242)\n",
      "Color 56: (196, 12, 242)\n",
      "Color 57: (216, 12, 242)\n",
      "Color 58: (235, 12, 242)\n",
      "Color 59: (242, 12, 229)\n",
      "Color 60: (242, 12, 209)\n",
      "Color 61: (242, 12, 189)\n",
      "Color 62: (242, 12, 170)\n",
      "Color 63: (242, 12, 150)\n",
      "Color 64: (242, 12, 130)\n",
      "Color 65: (242, 12, 111)\n",
      "Color 66: (242, 12, 91)\n",
      "Color 67: (242, 12, 71)\n",
      "Color 68: (242, 12, 52)\n",
      "Color 69: (242, 12, 32)\n"
     ]
    }
   ],
   "source": [
    "def generate_distinct_colors(n):\n",
    "    # Generate colors in HSL color space and convert to RGB\n",
    "    colors = []\n",
    "    for i in range(n):\n",
    "        hue = i / n\n",
    "        lightness = 0.5\n",
    "        saturation = 0.9\n",
    "        rgb = colorsys.hls_to_rgb(hue, lightness, saturation)\n",
    "        rgb = tuple(int(255 * x) for x in rgb)\n",
    "        colors.append(rgb)\n",
    "    return colors\n",
    "\n",
    "\n",
    "# Example usage\n",
    "n = 70\n",
    "distinct_colors = generate_distinct_colors(n)\n",
    "for i, color in enumerate(distinct_colors):\n",
    "    print(f\"Color {i}: {color}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoAAAACuCAYAAACm9LxMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAEGUlEQVR4nO3ZwWrVUBRA0ZMiOhBBof//a36CQumgBRsH4tA0YprG7rXGh9z7eCeweW9Z13UdAAAybl77AgAAnEsAAgDECEAAgBgBCAAQIwABAGIEIABAjAAEAIgRgAAAMQIQACDm3d7Bu9vbmYeHPw/czMyXmVk2HrJ35vPGzFnnXO2sHeesy8zjx+2ZHzPzfeMav2e+HTTzr2dd6S5HnrXOMo+z9WVdafnOPOtin+mspXiri37EC/408+F+e+StbvmF3oRdZ808zfu535i50vKdedaZn2nm093XZ2dm/uYXwK34m/m1FdubcczMWedcbWbHM9Y9M89c42ozV7rLsTMW/fp3GYv+0jM7nrHsmZlLbc3/tuUHzqzPzFxp+c6cOfMu+/kLGAAgRgACAMQIQACAGAEIABAjAAEAYgQgAECMAAQAiBGAAAAxAhAAIEYAAgDECEAAgBgBCAAQIwABAGIEIABAjAAEAIgRgAAAMQIQACBGAAIAxAhAAIAYAQgAECMAAQBiBCAAQIwABACIEYAAADECEAAgRgACAMQIQACAGAEIABAjAAEAYgQgAECMAAQAiBGAAAAxAhAAIEYAAgDECEAAgBgBCAAQIwABAGIEIABAjAAEAIgRgAAAMQIQACBGAAIAxAhAAIAYAQgAECMAAQBiBCAAQIwABACIEYAAADECEAAgRgACAMQIQACAGAEIABAjAAEAYgQgAECMAAQAiBGAAAAxAhAAIEYAAgDECEAAgBgBCAAQIwABAGIEIABAjAAEAIgRgAAAMQIQACBGAAIAxAhAAIAYAQgAECMAAQBiBCAAQIwABACIEYAAADECEAAgRgACAMQIQACAGAEIABAjAAEAYgQgAECMAAQAiBGAAAAxAhAAIEYAAgDECEAAgBgBCAAQIwABAGIEIABAjAAEAIgRgAAAMQIQACBGAAIAxAhAAIAYAQgAECMAAQBiBCAAQIwABACIEYAAADECEAAgRgACAMQIQACAGAEIABAjAAEAYgQgAECMAAQAiBGAAAAxAhAAIEYAAgDECEAAgBgBCAAQIwABAGIEIABAjAAEAIgRgAAAMQIQACBGAAIAxAhAAIAYAQgAECMAAQBiBCAAQIwABACIEYAAADECEAAgRgACAMQIQACAGAEIABAjAAEAYgQgAECMAAQAiBGAAAAxAhAAIEYAAgDECEAAgBgBCAAQIwABAGIEIABAjAAEAIgRgAAAMQIQACBGAAIAxAhAAIAYAQgAECMAAQBiBCAAQIwABACIEYAAADECEAAgRgACAMQIQACAGAEIABAjAAEAYgQgAECMAAQAiBGAAAAxy7qu62tfAgCA8/gFEAAgRgACAMQIQACAGAEIABAjAAEAYgQgAECMAAQAiBGAAAAxAhAAIOYnb7l8bKDpKP8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_colors(colors):\n",
    "    fig, ax = plt.subplots(figsize=(8, 2))\n",
    "    for i, color in enumerate(colors):\n",
    "        ax.add_patch(plt.Rectangle((i, 0), 1, 1, color=[c / 255.0 for c in color]))\n",
    "    ax.set_xlim(0, len(colors))\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_colors(distinct_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class IntensityValue:\n",
    "    def __init__(self, parent, value, level):\n",
    "        if level > 7:\n",
    "            raise Exception(\"There are no more colours left\")\n",
    "        self.value = value\n",
    "        self.parent = parent\n",
    "        self.level = level\n",
    "        self._child_a = None\n",
    "        self._child_b = None\n",
    "\n",
    "    @property\n",
    "    def child_a(self):\n",
    "        if self._child_a is None:\n",
    "            self._child_a = IntensityValue(self, self.value - (1 << (7 - self.level)), self.level + 1)\n",
    "        return self._child_a\n",
    "\n",
    "    @property\n",
    "    def child_b(self):\n",
    "        if self._child_b is None:\n",
    "            self._child_b = IntensityValue(self, self.value + (1 << (7 - self.level)), self.level + 1)\n",
    "        return self._child_b\n",
    "\n",
    "\n",
    "class IntensityValueWalker:\n",
    "    def __init__(self):\n",
    "        self.current = IntensityValue(None, 1 << 7, 1)\n",
    "\n",
    "    def move_next(self):\n",
    "        if self.current.parent is None:\n",
    "            self.current = self.current.child_a\n",
    "        elif self.current.parent.child_a == self.current:\n",
    "            self.current = self.current.parent.child_b\n",
    "        else:\n",
    "            levels_up = 1\n",
    "            self.current = self.current.parent\n",
    "            while self.current.parent is not None and self.current == self.current.parent.child_b:\n",
    "                self.current = self.current.parent\n",
    "                levels_up += 1\n",
    "            if self.current.parent is not None:\n",
    "                self.current = self.current.parent.child_b\n",
    "            else:\n",
    "                levels_up += 1\n",
    "            for _ in range(levels_up):\n",
    "                self.current = self.current.child_a\n",
    "\n",
    "\n",
    "class ColourGenerator:\n",
    "    def __init__(self):\n",
    "        self.index = 0\n",
    "        self.intensity_generator = IntensityValueWalker()\n",
    "        self.patterns = [\"{0}0000\", \"00{0}00\", \"0000{0}\", \"{0}{0}00\", \"{0}00{0}\", \"00{0}{0}\", \"{0}{0}{0}\"]\n",
    "\n",
    "    def next_colour(self):\n",
    "        intensity = self.next_intensity(self.index)\n",
    "        pattern = self.patterns[self.index % 7]\n",
    "        colour = pattern.format(intensity)\n",
    "        self.index += 1\n",
    "        return colour\n",
    "\n",
    "    def next_intensity(self, index):\n",
    "        if index == 0:\n",
    "            self.current_intensity = 255\n",
    "        elif index % 7 == 0:\n",
    "            self.intensity_generator.move_next()\n",
    "            self.current_intensity = self.intensity_generator.current.value\n",
    "        current_text = hex(self.current_intensity)[2:].upper()\n",
    "        if len(current_text) == 1:\n",
    "            current_text = \"0\" + current_text\n",
    "        return current_text\n",
    "\n",
    "\n",
    "def hex_to_rgb(hex_color):\n",
    "    return tuple(int(hex_color[i : i + 2], 16) for i in (0, 2, 4))\n",
    "\n",
    "\n",
    "def plot_colors(colors):\n",
    "    fig, ax = plt.subplots(figsize=(15, 5))\n",
    "    for i, color in enumerate(colors):\n",
    "        rgb = hex_to_rgb(color)\n",
    "        ax.add_patch(plt.Rectangle((i, 0), 1, 1, color=[c / 255.0 for c in rgb]))\n",
    "    ax.set_xlim(0, len(colors))\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Color 0: (255, 0, 0)\n",
      "Color 1: (0, 255, 0)\n",
      "Color 2: (0, 0, 255)\n",
      "Color 3: (255, 255, 0)\n",
      "Color 4: (255, 0, 255)\n",
      "Color 5: (0, 255, 255)\n",
      "Color 6: (255, 255, 255)\n",
      "Color 7: (64, 0, 0)\n",
      "Color 8: (0, 64, 0)\n",
      "Color 9: (0, 0, 64)\n",
      "Color 10: (64, 64, 0)\n",
      "Color 11: (64, 0, 64)\n",
      "Color 12: (0, 64, 64)\n",
      "Color 13: (64, 64, 64)\n",
      "Color 14: (192, 0, 0)\n",
      "Color 15: (0, 192, 0)\n",
      "Color 16: (0, 0, 192)\n",
      "Color 17: (192, 192, 0)\n",
      "Color 18: (192, 0, 192)\n",
      "Color 19: (0, 192, 192)\n",
      "Color 20: (192, 192, 192)\n",
      "Color 21: (32, 0, 0)\n",
      "Color 22: (0, 32, 0)\n",
      "Color 23: (0, 0, 32)\n",
      "Color 24: (32, 32, 0)\n",
      "Color 25: (32, 0, 32)\n",
      "Color 26: (0, 32, 32)\n",
      "Color 27: (32, 32, 32)\n",
      "Color 28: (96, 0, 0)\n",
      "Color 29: (0, 96, 0)\n",
      "Color 30: (0, 0, 96)\n",
      "Color 31: (96, 96, 0)\n",
      "Color 32: (96, 0, 96)\n",
      "Color 33: (0, 96, 96)\n",
      "Color 34: (96, 96, 96)\n",
      "Color 35: (160, 0, 0)\n",
      "Color 36: (0, 160, 0)\n",
      "Color 37: (0, 0, 160)\n",
      "Color 38: (160, 160, 0)\n",
      "Color 39: (160, 0, 160)\n",
      "Color 40: (0, 160, 160)\n",
      "Color 41: (160, 160, 160)\n",
      "Color 42: (224, 0, 0)\n",
      "Color 43: (0, 224, 0)\n",
      "Color 44: (0, 0, 224)\n",
      "Color 45: (224, 224, 0)\n",
      "Color 46: (224, 0, 224)\n",
      "Color 47: (0, 224, 224)\n",
      "Color 48: (224, 224, 224)\n",
      "Color 49: (16, 0, 0)\n",
      "Color 50: (0, 16, 0)\n",
      "Color 51: (0, 0, 16)\n",
      "Color 52: (16, 16, 0)\n",
      "Color 53: (16, 0, 16)\n",
      "Color 54: (0, 16, 16)\n",
      "Color 55: (16, 16, 16)\n",
      "Color 56: (48, 0, 0)\n",
      "Color 57: (0, 48, 0)\n",
      "Color 58: (0, 0, 48)\n",
      "Color 59: (48, 48, 0)\n",
      "Color 60: (48, 0, 48)\n",
      "Color 61: (0, 48, 48)\n",
      "Color 62: (48, 48, 48)\n",
      "Color 63: (80, 0, 0)\n",
      "Color 64: (0, 80, 0)\n",
      "Color 65: (0, 0, 80)\n",
      "Color 66: (80, 80, 0)\n",
      "Color 67: (80, 0, 80)\n",
      "Color 68: (0, 80, 80)\n",
      "Color 69: (80, 80, 80)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example usage\n",
    "generator = ColourGenerator()\n",
    "n = 70  # Number of colors to generate\n",
    "distinct_colors = [generator.next_colour() for _ in range(n)]\n",
    "\n",
    "for i, color in enumerate(distinct_colors):\n",
    "    rgb_color = hex_to_rgb(color)\n",
    "    print(f\"Color {i}: {rgb_color}\")\n",
    "\n",
    "# Visualize the colors\n",
    "plot_colors(distinct_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fradlin/miniconda3/envs/mask4d/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "def generate_distinct_colors_kmeans(n):\n",
    "    # Sample a large number of colors in RGB space\n",
    "    np.random.seed(0)\n",
    "    large_sample = np.random.randint(0, 256, (10000, 3))\n",
    "\n",
    "    # Apply k-means clustering to find n clusters\n",
    "    kmeans = KMeans(n_clusters=n).fit(large_sample)\n",
    "    colors = kmeans.cluster_centers_.astype(int)\n",
    "\n",
    "    return [tuple(color) for color in colors]\n",
    "\n",
    "\n",
    "# Example usage\n",
    "n = 25\n",
    "distinct_colors_kmeans = generate_distinct_colors_kmeans(n)\n",
    "# for i, color in enumerate(distinct_colors_kmeans):\n",
    "#     print(f\"Color {i}: {color}\")\n",
    "\n",
    "# Visualize the k-means colors\n",
    "plot_colors(distinct_colors_kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mask4d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
